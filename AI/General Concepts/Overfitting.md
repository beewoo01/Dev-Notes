# 🎯 Overfitting (과적합)

## 🧠 과적합이란?

> **훈련 데이터에는 높은 정확도를 보이지만, 새로운 데이터(테스트 데이터)에는 성능이 떨어지는 현상**  
> 즉, 모델이 훈련 데이터에 너무 집중하여 **노이즈나 특이점까지 외워버리는 문제**

---

## ⚠️ 과적합의 원인

| 원인                      | 설명 |
|---------------------------|------|
| **모델이 너무 복잡함**       | 파라미터 수가 많아 훈련 데이터를 쉽게 외움 |
| **데이터가 부족함**         | 적은 데이터를 학습하니 일반화가 어려움 |
| **훈련을 너무 오래함**       | 반복 학습하면서 점점 외우게 됨 |
| **노이즈가 많은 데이터**     | 중요하지 않은 정보까지 모델이 학습해버림 |

---

# ✅ Overfitting 완화 방법

---

## 1️⃣ 모델 경량화

- 모델 구조가 너무 복잡한 경우, **간단한 아키텍처로 변경**
- 과도한 파라미터 수를 줄여서 훈련 데이터에 대한 **의존도 감소**

---

## 2️⃣ Data Augmentation (데이터 증강)

### 🖼️ 이미지 분야

| 방법              | 설명 |
|-------------------|------|
| 회전 (Rotation)      | 이미지를 90°, 180° 회전 |
| 자르기 (Cropping)     | 일부분만 잘라서 사용 |
| 뒤집기 (Flip)         | 좌우/상하 반전 |
| 노이즈 추가           | 잡음 삽입 |
| 밝기/대비 조절       | 색감/밝기 변경 |
| Affine 변환         | 스케일/이동/기울이기 등 |
| Cutout             | 일부분 블록 처리 |
| Mixup / CutMix     | 이미지 섞기 또는 합치기 |

👉 활용 라이브러리: `torchvision.transforms`, `albumentations`

---

### 📝 텍스트 분야 (NLP)

| 방법                  | 설명 |
|------------------------|------|
| 동의어 치환             | 단어를 같은 의미의 다른 단어로 변경 |
| 단어 삭제/삽입         | 단어를 제거하거나 추가 |
| 문장 순서 섞기         | 단어 순서를 랜덤하게 변경 |
| Back Translation      | 언어를 번역 후 되돌려 표현을 다양화 |

---

### 📈 시계열 / 오디오 / 센서 데이터

| 방법               | 설명 |
|--------------------|------|
| Jittering           | 노이즈 추가 |
| Time Warping        | 시간 축 늘리기/줄이기 |
| Pitch/Speed 조절   | 오디오 음 높이/속도 조절 |

---

## 3️⃣ Dropout

- 학습 중 **랜덤하게 일부 노드를 끄고**, 과도한 의존을 막음

### 예시:
기존: 입력 → [노드 a, b, c, d] → 출력
Dropout 적용: 학습 중 무작위로 일부 노드 비활성화
→ A, D만 꺼짐 → 다음 배치엔 B, C만 꺼짐 → 반복



---

## 4️⃣ DropConnect

- **노드 자체가 아니라 노드 간의 연결(weight)**을 확률적으로 끊는 방식  
- Dropout의 일반화 형태

---

## 5️⃣ Regularization (정규화)

- Loss 함수에 **가중치의 크기**를 패널티로 추가하여 **복잡한 모델 억제**

\[
\text{Loss} = L + \lambda \|w\|_p^p
\]

### L1 Regularization (p = 1)

- 불필요한 특징 제거 → **희소한 모델 생성**
- 많은 가중치가 0으로 수렴

### L2 Regularization (p = 2)

- 모든 가중치를 조금씩 줄여서 **안정적인 학습**
- 과도한 가중치에 대한 제어로 **편향된 학습을 방지**

---

### ⚠️ λ (정규화 계수) 주의사항

| 상황 | 결과 |
|------|------|
| 너무 큼 | 예측보다 정규화에 집중 → **Underfitting** 발생 |
| 너무 작음 | 정규화 효과 없음 → **Overfitting** 위험 증가 |

---

## 🔚 마무리

- Overfitting은 학습된 모델이 **새로운 데이터를 일반화하지 못하는 상태**
- 다양한 기법들을 통해 이를 **완화하거나 예방**할 수 있음
- 최적의 방법은 **데이터 특성과 모델 목적**에 따라 다름

